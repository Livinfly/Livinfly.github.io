<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='CS149 课程视频 / 课件随想录。'><title>『学习笔记』CS149 (2024) | Livinfly's Blog</title><link rel=canonical href=https://livinfly.github.io/p/cs149_2024_note/><link rel=stylesheet href=/scss/style.min.2fa48f0dd0f0d33ca7625fe6827d8e10fb2960632d3596baf9186cede4604f55.css><meta property='og:title' content="『学习笔记』CS149 (2024)"><meta property='og:description' content="CS149 课程视频 / 课件随想录。"><meta property='og:url' content='https://livinfly.github.io/p/cs149_2024_note/'><meta property='og:site_name' content="Livinfly's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='学习笔记'><meta property='article:tag' content='CS149'><meta property='article:published_time' content='2025-08-30T06:00:56+00:00'><meta property='article:modified_time' content='2025-08-30T14:10:41+08:00'><meta property='og:image' content='https://livinfly.github.io/p/cs149_2024_note/cover.jpeg'><meta name=twitter:site content="@Mengmm_JhaiL"><meta name=twitter:creator content="@Mengmm_JhaiL"><meta name=twitter:title content="『学习笔记』CS149 (2024)"><meta name=twitter:description content="CS149 课程视频 / 课件随想录。"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://livinfly.github.io/p/cs149_2024_note/cover.jpeg'><link rel="shortcut icon" href=/favicon.png><link rel=apple-touch-icon href=/favicon.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-LKX43Y8KEL"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-LKX43Y8KEL")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=切换菜单>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_6155a7461c712b4f.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🤣</span></figure><div class=site-meta><h1 class=site-name><a href=/>Livinfly's Blog</a></h1><h2 class=site-description>想要留下点温暖的地方</h2></div></header><ol class=menu-social><li><a href=mailto:luojie3m@163.com target=_blank title=Email rel=me><svg class="icon icon-tabler icon-tabler-mail" width="44" height="44" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><rect x="3" y="5" width="18" height="14" rx="2"/><polyline points="3 7 12 13 21 7"/></svg></a></li><li><a href=https://github.com/Livinfly target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://twitter.com/Mengmm_JhaiL target=_blank title=Twitter rel=me><svg class="icon icon-tabler icon-tabler-brand-twitter" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M22 4.01c-1 .49-1.98.689-3 .99-1.121-1.265-2.783-1.335-4.38-.737S11.977 6.323 12 8v1c-3.245.083-6.135-1.395-8-4 0 0-4.182 7.433 4 11-1.872 1.247-3.739 2.088-6 2 3.308 1.803 6.913 2.423 10.034 1.517 3.58-1.04 6.522-3.723 7.651-7.742a13.84 13.84.0 00.497-3.753C20.18 7.773 21.692 5.25 22 4.009z"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>归档</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>搜索</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>友链</span></a></li><li><a href=/about/><svg class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>关于</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>暗色模式</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">目录</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#why-parallelism-why-efficiency>Why Parallelism? Why Efficiency?</a><ol><li><a href=#insttuction-level-parallelism-ilp-指令级并行>Insttuction Level Parallelism (ILP) 指令级并行</a></li></ol></li><li><a href=#a-model-multi-core-processor>A Model Multi-Core Processor</a><ol><li><a href=#part-1-parallel-execution>Part 1: parallel execution</a></li><li><a href=#part-2-accessing-memory>Part 2: accessing memory</a></li></ol></li><li><a href=#parallel-programming-abstractions>Parallel Programming Abstractions</a><ol><li><a href=#task-abstraction>task abstraction</a></li><li><a href=#three-models-of-communication-abstractions-通信模型抽象>Three models of communication (abstractions) 通信模型抽象</a></li></ol></li><li><a href=#parallel-programming-basics>Parallel Programming Basics</a><ol><li><a href=#分解-decomposition>分解 Decomposition</a></li><li><a href=#分配-assignment>分配 Assignment</a></li><li><a href=#编排-orchestration>编排 Orchestration</a></li><li><a href=#映射-mapping>映射 Mapping</a></li></ol></li><li><a href=#part-1-work-distribution-and-scheduling>Part 1: Work Distribution and Scheduling</a><ol><li><a href=#balancing-the-workload>Balancing the workload</a></li><li><a href=#schedule-fork-join-parallelism>Schedule fork-join parallelism</a></li></ol></li><li><a href=#part-ii-locality-communication-and-contention>Part II: Locality, Communication, and Contention</a><ol><li><a href=#shared-address-space-model>shared address space model</a></li><li><a href=#message-passing>Message passing</a></li><li><a href=#techniques-for-reducing-the-costs-of-communication>Techniques for reducing the costs of communication</a></li><li><a href=#general-program-optimization-tips>General program optimization tips</a></li></ol></li><li><a href=#gpu-architecture-and-cuda-programming>GPU Architecture and CUDA Programming</a><ol><li><a href=#graphics-101--gpu-history-for-fun>Graphics 101 + GPU history (for fun)</a></li><li><a href=#cuda-program>CUDA program</a></li></ol></li><li><a href=#data-parallel-thinking>Data-Parallel Thinking</a><ol><li><a href=#map-映射>Map 映射</a></li><li><a href=#fold-归约fold-left从左到右>Fold 归约（fold left，从左到右）</a></li><li><a href=#scan-扫描>Scan 扫描</a></li><li><a href=#gather--scatter-聚集--分发>Gather / scatter 聚集 / 分发</a></li></ol></li><li><a href=#distributed-data-parallel-computing-using-spark>Distributed Data-Parallel Computing Using Spark</a><ol><li><a href=#distributed-file-system-分布式文件系统>Distributed File System 分布式文件系统</a></li><li><a href=#mapreduce>MapReduce</a></li><li><a href=#apache-spark>Apache Spark</a></li></ol></li><li><a href=#efficiently-evaluating-dnns-software-solutions>Efficiently Evaluating DNNs (Software Solutions)</a></li><li><a href=#hardware-specialization>Hardware Specialization</a></li><li><a href=#programming-specialized-hardware>Programming Specialized Hardware</a></li><li><a href=#programming-specialized-hardware-ii--cache-coherence>Programming Specialized Hardware II + Cache Coherence</a></li><li><a href=#cache-coherence>Cache Coherence</a></li><li><a href=#lock-implementations-fine-grained-synchronization-and-lock-free-programming>Lock Implementations, Fine-Grained Synchronization and Lock-Free Programming</a></li><li><a href=#relaxed-consistency--domain-specific-programming-systems>Relaxed Consistency + Domain-Specific Programming Systems</a><ol><li><a href=#relaxed-memory-consistency>relaxed memory consistency</a></li><li><a href=#dsl-domain-specific-programming-languages>DSL (Domain-Specific programming languages)</a></li></ol></li><li><a href=#transactional-memory>Transactional Memory</a></li><li><a href=#transactions-ii--ask-me-anything-with-kayvon-and-kunle>Transactions II + Ask Me Anything with Kayvon and Kunle</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/cs149_2024_note/><img src=/p/cs149_2024_note/cover_hu_3637cfed5f8db042.jpeg srcset="/p/cs149_2024_note/cover_hu_3637cfed5f8db042.jpeg 800w, /p/cs149_2024_note/cover_hu_14854c4e58bf2002.jpeg 1600w" width=800 height=450 loading=lazy alt="Featured image of post 『学习笔记』CS149 (2024)"></a></div><div class=article-details><header class=article-category><a href=/categories/note/>笔记</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/cs149_2024_note/>『学习笔记』CS149 (2024)</a></h2><h3 class=article-subtitle>CS149 课程视频 / 课件随想录。</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>2025 年 8 月 30 日</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>阅读时长: 21 分钟</time></div></footer></div></header><section class=article-content><h1 id=cmu-15-41815-618-x-stanford-cs149-parallel-computer-architecture-and-programming>CMU 15-418/15-618 X Stanford CS149: Parallel Computer Architecture and Programming</h1><blockquote><p>封面来源：<a class=link href=https://x.com/toutenkou10105/status/1959553399827161120 target=_blank rel=noopener>@toutenkou10105</a>
<sup><svg aria-hidden="true" focusable="false" viewBox="0 0 100 100" width="12" height="12" class="icon outbound"><path fill="currentColor" d="M18.8 85.1h56c2.2.0 4-1.8 4-4v-32h-8v28h-48v-48h28v-8h-32c-2.2.0-4 1.8-4 4v56C14.8 83.3 16.6 85.1 18.8 85.1z"/><polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"/></svg></sup></p></blockquote><blockquote><p>15-418 Watch lecture video of 2016 spring and do assignments of 2018.</p><p>CS149 Watch lecture video of 2023 spring and do assignments of 2024.</p></blockquote><blockquote><p>[!TIP]</p><p>做 PA3 的时候，发现还是对照着做好一些，转向看 CS149 的 slides。
事实证明，有对应的，先看对应的；有新的，看新的。</p></blockquote><h2 id=why-parallelism-why-efficiency>Why Parallelism? Why Efficiency?</h2><p><strong>通信开销</strong>不能忽视，导致不能达到理想的加速比。</p><p><strong>负载不平衡</strong>，负载少的等待负载多的。</p><p><strong>Themes</strong>：</p><ul><li>设计、编写并行算法，并行思维，</li><li>了解底层硬件特性</li><li>efficiency 高效 ≠ 快，不同的应用场景看法不一样。</li></ul><h3 id=insttuction-level-parallelism-ilp-指令级并行>Insttuction Level Parallelism (ILP) 指令级并行</h3><p>单核处理，需要按照程序计数器 PC 串行运行，而实际上，不是所有指令都有严格前后依赖关系，可以同时运行。</p><p>通常的程序，ILP不会超过4,同时，虽然晶体管数量能以摩尔定律增长（之前），时钟频率瓶颈，当晶体管中都有不小的电容，此时要提高频率就需要增大电压，高电压，高发热，高能耗，就提不上去了。</p><p><strong>Power wall</strong></p><p>$\text{Dynamic power} \propto \text{capacitive} \cross \text{voltage}^2 \cross \text{frequency} $</p><p><strong>单指令流</strong>到达性能提升瓶颈，发热、能耗，ILP通常不能超过 4 倍；</p><p><strong>调度</strong>、<strong>通信开销</strong>、<strong>负载均衡</strong>，使得不能达到最高的加速比</p><h2 id=a-model-multi-core-processor>A Model Multi-Core Processor</h2><h3 id=part-1-parallel-execution>Part 1: parallel execution</h3><p>处理器，抽象组件：取指令、译码，执行指令，执行上下文。</p><p><img src=/p/cs149_2024_note/figures/image-20250618132131518.png width=737 height=933 srcset="/p/cs149_2024_note/figures/image-20250618132131518_hu_43f17fc0cd242a05.png 480w, /p/cs149_2024_note/figures/image-20250618132131518_hu_f2073694df06f1ce.png 1024w" loading=lazy alt="simple processor" class=gallery-image data-flex-grow=78 data-flex-basis=189px></p><p><strong>superscaler execution</strong> 超标量执行，在指令流中，两条指令是独立的，处理器发现并并行处理。</p><p>并不是真正意义上的并行，可能采用 pipeline 流水线技术。</p><p><img src=/p/cs149_2024_note/figures/image-20250618133035368.png width=702 height=921 srcset="/p/cs149_2024_note/figures/image-20250618133035368_hu_ed7951ef43e17545.png 480w, /p/cs149_2024_note/figures/image-20250618133035368_hu_918f06aee80ebfac.png 1024w" loading=lazy alt="two-way superscaler execution" class=gallery-image data-flex-grow=76 data-flex-basis=182px></p><p>快速单指令流的技术：<strong>内存预取</strong>、<strong>分支预测</strong>、<strong>乱序执行</strong> Out-of-Order Execution, OoOE。</p><p><strong>乱序执行</strong>，Instruction Window <strong>指令窗口</strong>，译码后先放入指令窗口，指令准备所需数据就绪就执行；有序提交，Re-order Buffer <strong>重排序缓冲区</strong>缓存乱序执行的结果，确保正确顺序更新。</p><p>这些技术虽然能加速，但也占据了处理器的很大<strong>空间</strong>，需要不少成本。</p><p><img src=/p/cs149_2024_note/figures/image-20250618134031626.png width=1576 height=1207 srcset="/p/cs149_2024_note/figures/image-20250618134031626_hu_eee36809c2c111d6.png 480w, /p/cs149_2024_note/figures/image-20250618134031626_hu_e41689a4b5bf3137.png 1024w" loading=lazy alt=加速单指令流的技术 class=gallery-image data-flex-grow=130 data-flex-basis=313px></p><p><strong>多核处理器</strong>如果遇到<strong>单指令流程序</strong>，不能加速。</p><p><img src=/p/cs149_2024_note/figures/image-20250618134944854.png width=1678 height=1092 srcset="/p/cs149_2024_note/figures/image-20250618134944854_hu_88c55a00d9697a2b.png 480w, /p/cs149_2024_note/figures/image-20250618134944854_hu_920b460a68690e4a.png 1024w" loading=lazy alt="two cores" class=gallery-image data-flex-grow=153 data-flex-basis=368px></p><p>标量程序与向量处理器，并不能加速，需要对应，SSE、AVX 指令，是 SIMD 指令。</p><p><img src=/p/cs149_2024_note/figures/image-20250618140014427.png width=1724 height=1167 srcset="/p/cs149_2024_note/figures/image-20250618140014427_hu_d608e558b61ae7a8.png 480w, /p/cs149_2024_note/figures/image-20250618140014427_hu_42dab3a8e0b72d36.png 1024w" loading=lazy alt="SIMD processing" class=gallery-image data-flex-grow=147 data-flex-basis=354px></p><p><strong>多核</strong>和<strong>SIMD</strong>是正交的，可以结合。</p><p>多核、多线程、多核执行与SIMD执行，有区别，SIMD 需要<strong>共享指令流</strong>。</p><p>现代的非朴素的编译器，只有在判断条件符合的时候，才会尝试给执行里面的内容。</p><p><strong>术语</strong> Terminology</p><ul><li><p>Instruction stream coherence <strong>指令流一致性</strong></p><p>一些列不同的逻辑序列能共享相同的指令流，有指令流一致性，在 SIMD 架构下运行的很好。</p></li><li><p>Divergent execution <strong>发散执行</strong></p><p>缺乏一致性。</p></li><li><p>cache coherence <strong>缓存一致性</strong></p></li></ul><p>SIMD on CPUs，显式的。</p><p><img src=/p/cs149_2024_note/figures/image-20250618195046367.png width=1196 height=729 srcset="/p/cs149_2024_note/figures/image-20250618195046367_hu_1d460f900b974035.png 480w, /p/cs149_2024_note/figures/image-20250618195046367_hu_453907a0a54829c0.png 1024w" loading=lazy alt="SIMD execution on moddern CPUs" class=gallery-image data-flex-grow=164 data-flex-basis=393px></p><p>SIMD on GPUs，隐式的，更高层级的抽象。</p><p><img src=/p/cs149_2024_note/figures/image-20250618195301914.png width=1224 height=615 srcset="/p/cs149_2024_note/figures/image-20250618195301914_hu_ccc61668620b458a.png 480w, /p/cs149_2024_note/figures/image-20250618195301914_hu_dd7d0d3dc85adc13.png 1024w" loading=lazy alt="SIMD execution on many modern GPUs" class=gallery-image data-flex-grow=199 data-flex-basis=477px></p><p>描述机器，X <strong>cores</strong>, Y SIMD ALUs per core (<strong>SIMD width</strong>)</p><p>$\text{FLOPS} = \text{Frenquency(Hz)} \cross \text{Cores} \cross \text{SIMD width} \cross \text{MAD}$</p><p>A核B宽SIMD 与 B核A宽SIMD：指令流在 8 条一组下的一致性，可能不如 4 条一组。</p><p><strong>总结</strong></p><p>若干并行运算的方式：</p><ul><li><p><strong>Multi-core</strong>，多核，多处理核</p><p>thread-level 线程级并行（不同指令流在不同核上）</p><p>软件决定什么时候创建线程 e.g. pthreads</p></li><li><p><strong>SIMD</strong>，多ALUs，被同一条指令流控制（within a core）</p><p>为 data-parallel 数据集并行设计，控制的开销被 ALUs 均摊</p><p>向量化被编译器（显式SIMD）、runtime 运行时完成。</p><p>需要被说明，或者需要被高级编译器的循环分析</p></li><li><p><strong>Superscalar</strong>，超标量，利用一条指令流的 ILP 指令级并行(within a core)</p><p>硬件自动、动态的并行化。</p><p>超标量架构的CPU核心本身在一个时钟周期内就能执行多条指令。</p></li></ul><p>（增加资源来提高峰值计算）</p><h3 id=part-2-accessing-memory>Part 2: accessing memory</h3><p><strong>术语</strong>，Terminology</p><ul><li><p><strong>Memory latency</strong>，内存延迟</p><p>内存请求的总时间，存/取。</p><p><strong>latency</strong> 延迟是衡量某时间所需时间长短的指标。</p><p>e.g. 更快的车、更高的限速标准。</p></li><li><p><strong>Memory bandwidth</strong>，内存带宽</p><p><strong>bandwidth</strong> 带宽是单位时间内发生多少事情的指标。</p><p>e.g. 增加车道。</p></li></ul><p>（两者的相关性取决于重叠处理程度）</p><p><strong>stalls</strong>，在有依赖先前的指令的时候，处理器需要停顿。</p><p>比如，内存读流水线并行，可以提高带宽，但因为对比很长的读取周期，延迟可能没有太多变化。</p><p><strong>cache</strong>，把<strong>降低内存加载的延迟</strong>，length of stalls（reduce latency）</p><p><strong>prefetch</strong>，减少 stalls（<strong>hides</strong> latency）</p><p>用 <strong>multi-threading</strong> 多线程来隐藏 <strong>stalls</strong> 停顿，切换线程；各自的寄存器组，对应各自的执行上下文，即可以在<strong>同一处理器</strong>下运行<strong>多条指令流</strong>。</p><p>缓解等待耗时长的操作（e.g. 内存访问），处理器的空闲时间变少了，处理器性能发挥得更加充分。</p><p>和 OS 的切换概念是相同的，机制是不同的，如果让 OS 来管理这个切换，开销大。</p><p><img src=/p/cs149_2024_note/figures/image-20250618210453820.png width=1311 height=906 srcset="/p/cs149_2024_note/figures/image-20250618210453820_hu_ae97502645ea4821.png 480w, /p/cs149_2024_note/figures/image-20250618210453820_hu_f0bcf3596f6afe52.png 1024w" loading=lazy alt="Hiding stalls with multi-threading" class=gallery-image data-flex-grow=144 data-flex-basis=347px></p><p>问题：上下文存储空间是有限的，Trade off。</p><p>更多但更小的上下文（更强的<strong>延迟隐藏</strong>能力）</p><p>更少但更大的上下文（更大的 L1 cache）</p><p>没有增加计算资源，提高了高效利用资源的能力。</p><p>这种模式有多个不同的版本：</p><ul><li><p><strong>Interleaved multi-threading</strong> (a.k.a. tmporal multi-threading) 交叉多线程 / 时间多线程</p><p>前面提到的技术</p></li><li><p><strong>Simultaneous multi-threading</strong> (SMT) 同时多线程 / 同步多线程</p><p>每个时钟周期，核心从多个线程中选择指令去在 ALU 上运行</p><p>superscalar 的设计的扩展</p><p>e.g. Intel Hyper-threading (2 threads per core)</p></li></ul><p><strong>多线程</strong>的代价，假定 cache 没用，不是<strong>降低延迟</strong>，是通过做别的事情来<strong>隐藏延迟</strong>。</p><p>这也是 GPU 每个核心有很强的计算能力、很多线程，但是只有不大的缓存。</p><p>CPU 的每个核心有两个线程。</p><p>CPU 的设计是为了降低延迟；GPU 的设计是精细设计、减小 cache 体积，使得能集成大量的 ALU 来计算。</p><p><img src=/p/cs149_2024_note/figures/image-20250618215832904.png width=1252 height=748 srcset="/p/cs149_2024_note/figures/image-20250618215832904_hu_7c27d0951b2764e8.png 480w, /p/cs149_2024_note/figures/image-20250618215832904_hu_84058282f6f4e4ae.png 1024w" loading=lazy alt="GPUs: Extreme throughput-oriented processors" class=gallery-image data-flex-grow=167 data-flex-basis=401px></p><p>一个 Warp 的完整上下文，实际上是：</p><p>1 个程序计数器 (PC) 和 32 组通用目的寄存器 (General-Purpose Registers, GPRs)，每个线程独享一组。</p><p>48 个交叉 warp 是 48 个执行上下文。</p><p><img src=/p/cs149_2024_note/figures/image-20250618220310075.png width=1244 height=695 srcset="/p/cs149_2024_note/figures/image-20250618220310075_hu_238194332d919625.png 480w, /p/cs149_2024_note/figures/image-20250618220310075_hu_2cdac4172972c607.png 1024w" loading=lazy alt="NVIDIA GTX 480: more detail (just for the curious)" class=gallery-image data-flex-grow=178 data-flex-basis=429px></p><p>ALU 运行在两倍于芯片其他部分的时钟频率，所以，相当于是 32。</p><p>这个是 <strong>hot clocking</strong> (<strong>shader clock</strong>)，但因为能耗太高，下一代架构就砍掉了（x</p><p><strong>思维实验</strong></p><p><img src=/p/cs149_2024_note/figures/image-20250618214217195.png width=1283 height=979 srcset="/p/cs149_2024_note/figures/image-20250618214217195_hu_ab2471c2b6a44028.png 480w, /p/cs149_2024_note/figures/image-20250618214217195_hu_e3df19e06dd45c9.png 1024w" loading=lazy alt=思维实验 class=gallery-image data-flex-grow=131 data-flex-basis=314px></p><p>是不是一个好的并行程序。</p><p>pros: 可 SIMD，可利用多核，不可以隐藏延迟（？）</p><p>cons: 所需的内存带宽太大了，每个计算所产生的内存访问需要大大超出了现在的计算机设计。</p><p>实际上，由于内存带宽限制，在 CPU 与 GPU 上跑得差不多。</p><p>一个周期的 MADs $Core \cross SIMD \ function\ units = 15 \cross 32 = 480 $</p><p><img src=/p/cs149_2024_note/figures/image-20250619142131382.png width=1617 height=1096 srcset="/p/cs149_2024_note/figures/image-20250619142131382_hu_d529aaad6160253c.png 480w, /p/cs149_2024_note/figures/image-20250619142131382_hu_898c374c74eb741f.png 1024w" loading=lazy alt="Summary: four superscalar, SIMD, multi-threaded cores" class=gallery-image data-flex-grow=147 data-flex-basis=354px></p><p>一些<strong>术语</strong>：</p><ul><li>Multi-core processor</li><li>SIMD execution</li><li>Coherent control flow</li><li>Hardware multi-threading<ul><li>Interleaved multi-threading</li><li>Simultaneous multi-threading</li></ul></li><li>Memory latency</li><li>Memory bandwidth</li><li>Bandwideth bound application</li><li>Arithmetic intensity</li></ul><p>（高效利用资源）</p><h2 id=parallel-programming-abstractions>Parallel Programming Abstractions</h2><p>Abstraction vs. implementation</p><h3 id=task-abstraction>task abstraction</h3><p><img src=/p/cs149_2024_note/figures/image-20250619160433375.png width=1173 height=809 srcset="/p/cs149_2024_note/figures/image-20250619160433375_hu_70ac84675dea49d5.png 480w, /p/cs149_2024_note/figures/image-20250619160433375_hu_d86ffae45b4db4d5.png 1024w" loading=lazy alt="ISPC: abstraction vs. implementation" class=gallery-image data-flex-grow=144 data-flex-basis=347px></p><p>Hyper-threading，超标量 + 多线程。</p><p>ISPC <strong>gang abstraction</strong> by SIMD on one core, programming instances</p><p>不同的映射方式 map，抽象的理解方式和实际的执行方式的不同。</p><p>实际不同实例是一起执行的，所以第一种才是连续的内存访问。</p><ol><li><p><img src=/p/cs149_2024_note/figures/image-20250721014101696.png width=1142 height=792 srcset="/p/cs149_2024_note/figures/image-20250721014101696_hu_1e56ba28eef7d7b.png 480w, /p/cs149_2024_note/figures/image-20250721014101696_hu_bf34b8b23ecf98b.png 1024w" loading=lazy alt="Interleaved assignment" class=gallery-image data-flex-grow=144 data-flex-basis=346px></p><p><img src=/p/cs149_2024_note/figures/image-20250721014641812.png width=1182 height=872 srcset="/p/cs149_2024_note/figures/image-20250721014641812_hu_2052218fa39012bd.png 480w, /p/cs149_2024_note/figures/image-20250721014641812_hu_253c283c0027e70.png 1024w" loading=lazy alt="Schedule: interleaved assignment" class=gallery-image data-flex-grow=135 data-flex-basis=325px></p></li><li><p><img src=/p/cs149_2024_note/figures/image-20250721014229455.png width=1138 height=778 srcset="/p/cs149_2024_note/figures/image-20250721014229455_hu_311269fdf1557653.png 480w, /p/cs149_2024_note/figures/image-20250721014229455_hu_e73c525fb19fea9d.png 1024w" loading=lazy alt="Block assignment" class=gallery-image data-flex-grow=146 data-flex-basis=351px></p><p><img src=/p/cs149_2024_note/figures/image-20250721014659103.png width=1107 height=887 srcset="/p/cs149_2024_note/figures/image-20250721014659103_hu_b86795bfb8548af1.png 480w, /p/cs149_2024_note/figures/image-20250721014659103_hu_10ac717d754adc47.png 1024w" loading=lazy alt="Schedule: block assignment" class=gallery-image data-flex-grow=124 data-flex-basis=299px></p></li></ol><p>ISPC 只涉及到 SIMD 的实现，不涉及到多核处理。</p><p>在单个执行线程内，利用单个执行上下文，通过 SIMD 指令完成操作。</p><p>不能在 ISPC 函数中调用 ISPC 函数。</p><p>ISPC 归约求和，<code>reduce_add()</code>，</p><p><img src=/p/cs149_2024_note/figures/image-20250721020234887.png width=1096 height=851 srcset="/p/cs149_2024_note/figures/image-20250721020234887_hu_fbf77809cbc11227.png 480w, /p/cs149_2024_note/figures/image-20250721020234887_hu_c6ec70b1d0dc7bd7.png 1024w" loading=lazy alt="ISPC: sum reduction" class=gallery-image data-flex-grow=128 data-flex-basis=309px></p><p>spawn <strong>gang</strong>, <strong>tasks</strong>。</p><p>向上、向下表达的层是什么？</p><p><img src=/p/cs149_2024_note/figures/image-20250619164240166.png width=1194 height=716 srcset="/p/cs149_2024_note/figures/image-20250619164240166_hu_69ec796ed34b2df3.png 480w, /p/cs149_2024_note/figures/image-20250619164240166_hu_d94fbc05650e4b09.png 1024w" loading=lazy alt="Example: expressing parallelism with ISPC" class=gallery-image data-flex-grow=166 data-flex-basis=400px></p><h3 id=three-models-of-communication-abstractions-通信模型抽象>Three models of communication (abstractions) 通信模型抽象</h3><p><strong>Shared address space</strong></p><p>共享地址空间通信模型，抽象化共享内存地址空间。</p><p>线程之间通过<strong>读/写</strong>共享变量来通信。</p><p>同步原语 e.g. locks，也是通过共享变量实现的。</p><p><img src=/p/cs149_2024_note/figures/image-20250721021846147.png width=641 height=413 srcset="/p/cs149_2024_note/figures/image-20250721021846147_hu_1dd5af821630faf0.png 480w, /p/cs149_2024_note/figures/image-20250721021846147_hu_1cfcc19115fded18.png 1024w" loading=lazy alt="Dance-hall 组织（一部分人在一边，另一部分在另一边）" class=gallery-image data-flex-grow=155 data-flex-basis=372px></p><p>如果想要放很多的核心，很容易产生瓶颈，所以出现设置<strong>分区</strong>，Non-uniform memory access (NUMA)，比如 cache。</p><p><strong>Message passing</strong></p><p>消息传递模型，线程操作自己的私有地址空间，通过显式的<strong>收/发</strong>信息来通信。</p><p><strong>Data-parallel</strong></p><p>对数组中的元素执行同样的操作，如 SPMD 编程（ISPC），集合中的<strong>元素是独立</strong>的。</p><p><strong>stream programming</strong> 流式编程</p><p><img src=/p/cs149_2024_note/figures/image-20250721134930531.png width=594 height=417 srcset="/p/cs149_2024_note/figures/image-20250721134930531_hu_7d20471cda56aad8.png 480w, /p/cs149_2024_note/figures/image-20250721134930531_hu_d85444a692b4c4d.png 1024w" loading=lazy alt="stream programming" class=gallery-image data-flex-grow=142 data-flex-basis=341px></p><p><strong>优点</strong>：如上图，从 read - operate 1 - write - read - operate 2 - write 变成 read - operate 1 & 2 - write，减少了内存带宽的压力。</p><p>（给定相关信息，编译器能够优化）</p><p><strong>缺点</strong>：需要引入新的操作符。</p><p>数据流操作：分散<strong>scatter</strong>和聚集<strong>gather</strong>。</p><p><img src=/p/cs149_2024_note/figures/image-20250721135622881.png width=1206 height=787 srcset="/p/cs149_2024_note/figures/image-20250721135622881_hu_33ed5330e95cc29b.png 480w, /p/cs149_2024_note/figures/image-20250721135622881_hu_2a1653d85a9fc8c1.png 1024w" loading=lazy alt="scatter and gather" class=gallery-image data-flex-grow=153 data-flex-basis=367px></p><p>cache 命中问题？所以，这样的指令是 costly 的。</p><p><strong>一段代码意味着什么，程序语义是什么，怎么实现的。</strong></p><h2 id=parallel-programming-basics>Parallel Programming Basics</h2><p>创建并行程序：分解Decomposition, 分配Assignment, 编排Orchestration, 映射Mapping。</p><p><img src=/p/cs149_2024_note/figures/image-20250721140717230.png width=1251 height=932 srcset="/p/cs149_2024_note/figures/image-20250721140717230_hu_54f56427d8e62ac1.png 480w, /p/cs149_2024_note/figures/image-20250721140717230_hu_fa37c602ae32caa4.png 1024w" loading=lazy alt=创建并行程序 class=gallery-image data-flex-grow=134 data-flex-basis=322px></p><h3 id=分解-decomposition>分解 Decomposition</h3><p>分解<strong>不一定是静态</strong>的，创建至少<strong>足够的任务</strong>去让执行单元繁忙。</p><p>关键，独立<strong>identifying dependencies</strong>。</p><p>阿姆达尔定律 <strong>Amdahl&rsquo;s law</strong>：</p><p>需要顺序执行的部分，s，$\text{speedup} \le \frac{1}{s + \frac{1-s}{p}}$。</p><p>程序员需要声明哪些部分是<strong>独立</strong>的。</p><h3 id=分配-assignment>分配 Assignment</h3><p>在 ISPC 的例子中，使用 <code>foreach</code>比手写 <code>programIndex</code>与 <code>programCount</code>要更有可移植性，因为<strong>更高层级的抽象</strong>可以让编译器根据硬件去选择优化。</p><p>系统上创建线程的开销，不可忽视，特别是创建的线程数很多的时候。</p><p>一般创建线程数就是<strong>执行上下文</strong>的总数，然后作为 worker pool，用 next_task 等。</p><h3 id=编排-orchestration>编排 Orchestration</h3><p>略，后续课程具体讲。</p><p>包括结构化通信、同步、组织数据结构、安排任务。</p><p>减小通信/同步开销，保持局部性等。</p><h3 id=映射-mapping>映射 Mapping</h3><p>映射"threads"(&ldquo;workers&rdquo;)到硬件执行单元。</p><ol><li>系统 OS，e.g. pthread to HW execution context</li><li>编译器 compiler，e.g. ISPC program instances to vector instruction lanes</li><li>硬件 hardware，e.g. CUDA thread block to GPU cores</li></ol><p><img src=/p/cs149_2024_note/figures/image-20250721145556556.png width=1095 height=279 srcset="/p/cs149_2024_note/figures/image-20250721145556556_hu_c603e62e45196cc9.png 480w, /p/cs149_2024_note/figures/image-20250721145556556_hu_9d5c9f376244c6a5.png 1024w" loading=lazy alt=映射选择 class=gallery-image data-flex-grow=392 data-flex-basis=941px></p><p>用 Gauss-Seidel 解决偏微分方程 PDE。</p><p>从左上至右下，每个元素取十字相邻的五个元素（包括自己）的均值。（是直接利用最新版本的数据更新的）</p><p><img src=/p/cs149_2024_note/figures/image-20250721150539888.png width=1180 height=854 srcset="/p/cs149_2024_note/figures/image-20250721150539888_hu_8b6ae00e84f17598.png 480w, /p/cs149_2024_note/figures/image-20250721150539888_hu_1a3eed4faccbb334.png 1024w" loading=lazy alt=找到独立性 class=gallery-image data-flex-grow=138 data-flex-basis=331px></p><p>如果强行要求并行版本的结果与串行执行版本一致，我们找到的独立/并行的元素是<strong>对角线</strong>，<strong>多轮迭代</strong>同时进行，仍然效果没有那么好。</p><p>改变算法执行顺序，更加适合并行化（尽管会带来少许结果的不同）。</p><p><img src=/p/cs149_2024_note/figures/image-20250721151222485.png width=1193 height=842 srcset="/p/cs149_2024_note/figures/image-20250721151222485_hu_2736523f88f52e2b.png 480w, /p/cs149_2024_note/figures/image-20250721151222485_hu_e6a108d93c1c428e.png 1024w" loading=lazy alt=新方法 class=gallery-image data-flex-grow=141 data-flex-basis=340px></p><p>打破原本的依赖关系。</p><p><img src=/p/cs149_2024_note/figures/image-20250721151316983.png width=1226 height=913 srcset="/p/cs149_2024_note/figures/image-20250721151316983_hu_cdae2119b1819a87.png 480w, /p/cs149_2024_note/figures/image-20250721151316983_hu_6cafbd32050f313b.png 1024w" loading=lazy alt=不同的分配方式 class=gallery-image data-flex-grow=134 data-flex-basis=322px></p><p>交替执行红黑块。</p><p>wait &lt;=> <strong>barrier</strong>，<code>barrier(myBarrier, NUM_PROCESSORS)</code>都需要到，才会继续运行，尽可能减少 barriers。</p><p>因为不少应用的的解法来自统计计算，所以可以去为了提高并行度，而降低些准确性。</p><p><img src=/p/cs149_2024_note/figures/image-20250721151431524.png width=1195 height=574 srcset="/p/cs149_2024_note/figures/image-20250721151431524_hu_e12dc0d14eebfd44.png 480w, /p/cs149_2024_note/figures/image-20250721151431524_hu_6a3be140facec55.png 1024w" loading=lazy alt=依赖（数据流） class=gallery-image data-flex-grow=208 data-flex-basis=499px></p><p>需要通信的情况。</p><p><img src=/p/cs149_2024_note/figures/image-20250721151547094.png width=1236 height=885 srcset="/p/cs149_2024_note/figures/image-20250721151547094_hu_1d404c9036620ab0.png 480w, /p/cs149_2024_note/figures/image-20250721151547094_hu_6991cf032a0c6a9a.png 1024w" loading=lazy alt=通信结果 class=gallery-image data-flex-grow=139 data-flex-basis=335px></p><p>编排 Orchestration 使用花括号、系统函数。</p><h2 id=part-1-work-distribution-and-scheduling>Part 1: Work Distribution and Scheduling</h2><p>核心目标（其中有冲突）：</p><ul><li>均衡负载</li><li>减少通信（stalls）</li><li>减少额外工作（overhead）</li></ul><p>建议一、<strong>总是先实现最简单的解决方法，再测试性能，判断是否需要做得更好。</strong></p><h3 id=balancing-the-workload>Balancing the workload</h3><p><strong>static assignment</strong></p><p>静态分配，简单、不会有额外运行时的开销。</p><p>当工作的花销和任务的数量是可预测的时候，可以去提前想出好的分配方案。</p><p>就算每一份工作不是平衡的，只要是可预测的，也可以提前调度。</p><p><strong>&ldquo;semi-static&rdquo; assignment</strong></p><p>较近的未来是可预测的，如自适应网络。</p><p>分配方案在重新调整的时候是静态的。</p><p>（重建分配是静态的）</p><p><strong>dynamic assignment</strong></p><p>在运行时确定，lock。</p><p>控制同步的开销，<strong>增大任务粒度</strong>（一次通信做更多的事情）</p><p><strong>均衡任务大小</strong>（均衡负载和最小化分配开销之前）</p><p><strong>优化任务调度</strong>（把大任务也切成小任务来调度、可能增加同步开销，关注量而非数量调度、先分配大任务）</p><p><strong>分布式队列降低同步开销</strong>（从别的任务队列中「偷」任务）</p><p>有依赖的任务队列？</p><h3 id=schedule-fork-join-parallelism>Schedule fork-join parallelism</h3><p>大任务分解成若干个小任务并行执行，然后将这些小任务的结果合并，分治。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-c++ data-lang=c++><span class=line><span class=cl><span class=c1>// Clik Plus（C++ 扩展，MIT，公开标准）
</span></span></span><span class=line><span class=cl><span class=c1>// 函数并行的抽象
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>clik_spawn</span> <span class=nf>foo</span><span class=p>(</span><span class=n>args</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=n>clik_spawn</span> <span class=nf>bar</span><span class=p>();</span>
</span></span><span class=line><span class=cl><span class=n>clik_spawn</span> <span class=nf>fizz</span><span class=p>();</span>
</span></span><span class=line><span class=cl><span class=n>buzz</span><span class=p>();</span>
</span></span><span class=line><span class=cl><span class=n>clik_sync</span><span class=p>;</span>
</span></span></code></pre></td></tr></table></div></div><p>抽象层面想好了，具体实现的话，如果为每一个 cilk_spawn 创建一个线程， cilk_sync 使用堵塞，显然会有很重的线程创建开销。</p><p>具体地，我们可以使用<strong>线程池</strong>的方式实现。</p><p><strong>Child Stealing vs Continuation Stealing</strong></p><p><strong>续体优先（Run continuation first, child stealing）</strong>：</p><ul><li>BFS</li><li>这种策略是让父线程继续执行 <code>cilk_spawn</code> 之后的代码（在此例中为 <code>bar();</code>），而将 <code>foo()</code> 排入可执行任务队列，以供当前线程或其他线程稍后执行。</li><li><strong>优点</strong>：父线程继续执行可能减少上下文切换的开销，并利用现有的局部性。</li><li><strong>缺点</strong>：如果 <code>foo()</code> 很重要或者非常耗时，推迟其执行可能会影响程序的整体性能。</li></ul><p><strong>子任务优先（Run child first, continuation stealing）</strong>：</p><ul><li>DFS</li><li>这种策略是立即执行 <code>foo()</code>，而将续体（<code>bar();</code>）加入任务队列，以供其他线程"窃取"（stealing）执行。</li><li><strong>优点</strong>：这可以快速启动可能的重要或复杂的并行任务，尽快获得其计算结果。</li><li><strong>缺点</strong>：可能导致父线程的局部数据和状态被挂起，增加了线程间切换的可能性。</li></ul><p><strong>steal 从工作队列的队头还是队尾 steal？</strong></p><ul><li>设计 deque 双端队列。</li><li>当前 thread 从 botttom push/pop，其他 thread 从 top 进行 steal，避免锁同步。</li></ul><p>只要空闲，还有任务可以偷，就偷。</p><p>堵塞之后的任务不一定还在主线程上运行。</p><h2 id=part-ii-locality-communication-and-contention>Part II: Locality, Communication, and Contention</h2><h3 id=shared-address-space-model>shared address space model</h3><p>抽象的具体实现。</p><p><strong>共享地址空间硬件结构</strong></p><p><img src=/p/cs149_2024_note/figures/image-20250817131638619.png width=840 height=908 srcset="/p/cs149_2024_note/figures/image-20250817131638619_hu_19f44e54bf905594.png 480w, /p/cs149_2024_note/figures/image-20250817131638619_hu_19edec7c06e83ed8.png 1024w" loading=lazy alt="Intel Core i7 (quad core)" class=gallery-image data-flex-grow=92 data-flex-basis=222px></p><p><img src=/p/cs149_2024_note/figures/image-20250817131718623.png width=2588 height=1424 srcset="/p/cs149_2024_note/figures/image-20250817131718623_hu_d6ffe8ef4e76a34d.png 480w, /p/cs149_2024_note/figures/image-20250817131718623_hu_7585415d1adab39a.png 1024w" loading=lazy alt="Intel’s ring interconnect" class=gallery-image data-flex-grow=181 data-flex-basis=436px></p><p><img src=/p/cs149_2024_note/figures/image-20250817131745767.png width=1036 height=1078 srcset="/p/cs149_2024_note/figures/image-20250817131745767_hu_1229556bcea6547.png 480w, /p/cs149_2024_note/figures/image-20250817131745767_hu_da04065f8205e360.png 1024w" loading=lazy alt="crossbar interconnect" class=gallery-image data-flex-grow=96 data-flex-basis=230px></p><p><img src=/p/cs149_2024_note/figures/image-20250817131822308.png width=1302 height=726 srcset="/p/cs149_2024_note/figures/image-20250817131822308_hu_ec8d446321ab1061.png 480w, /p/cs149_2024_note/figures/image-20250817131822308_hu_795990ed98d3b7e3.png 1024w" loading=lazy alt="Non-uniform memory access (NUMA)" class=gallery-image data-flex-grow=179 data-flex-basis=430px></p><h3 id=message-passing>Message passing</h3><p><code>send()</code>, <code>recv()</code>。</p><p><strong>Arithmetic intensity</strong> 计算强度</p><p>$\text{Arithmetic intensity} = \frac{\text{amount of computation (e.g., instructions)}}{\text{amount of communication (e.g., bytes)}}$，越高越好。</p><p>如果分子是<strong>计算的执行时间</strong>，这个比率给出了代码<strong>平均所需的带宽</strong>。</p><p>$\frac{1}{\text{&ldquo;Arithmetic intensity&rdquo;}} = \text{communication-to-computation rate}$</p><p><strong>通信的两个原因</strong>：</p><ul><li><p>inherent communication，算法成立的固有的通信</p><p>分配得更加合理，可以减少固有通信。</p><p><img src=/p/cs149_2024_note/figures/image-20250817141046683.png width=1812 height=994 srcset="/p/cs149_2024_note/figures/image-20250817141046683_hu_2746b9fa6b56eada.png 480w, /p/cs149_2024_note/figures/image-20250817141046683_hu_de7c4f694c2f12b4.png 1024w" loading=lazy alt="不同的分配方式 1" class=gallery-image data-flex-grow=182 data-flex-basis=437px></p><p><img src=/p/cs149_2024_note/figures/image-20250817141231605.png width=2168 height=994 srcset="/p/cs149_2024_note/figures/image-20250817141231605_hu_546d63e65a70b2d1.png 480w, /p/cs149_2024_note/figures/image-20250817141231605_hu_af0a751f776160b.png 1024w" loading=lazy alt="不同的分配方式 2" class=gallery-image data-flex-grow=218 data-flex-basis=523px></p></li><li><p>人为造成的（系统的具体实现导致的）</p><p>如和 cache 的表现相关、系统的数据转移的最小粒度、实际上只要写入，但是 cache 还是会读入 cache line。</p></li></ul><h3 id=techniques-for-reducing-the-costs-of-communication>Techniques for reducing the costs of communication</h3><p><strong>提升空间局部性</strong></p><ul><li><p>改变网格遍历顺序</p><p>「块状 blocked」遍历顺序 cache</p></li><li><p>「融合 fusing」循环</p><p>提升计算强度 arithmetic intensity</p><p>load / store per arithmetic</p><p>（存在功能模块化、代码可读性等的取舍）</p></li></ul><p><img src=/p/cs149_2024_note/figures/image-20250817143957814.png width=926 height=910 srcset="/p/cs149_2024_note/figures/image-20250817143957814_hu_a59483a5c8776483.png 480w, /p/cs149_2024_note/figures/image-20250817143957814_hu_f93aea01fd15c204.png 1024w" loading=lazy alt="blocked iteration" class=gallery-image data-flex-grow=101 data-flex-basis=244px></p><p><img src=/p/cs149_2024_note/figures/image-20250817144535387.png width=1952 height=1146 srcset="/p/cs149_2024_note/figures/image-20250817144535387_hu_5792ee28975ff277.png 480w, /p/cs149_2024_note/figures/image-20250817144535387_hu_f9ff69c32f499b5f.png 1024w" loading=lazy class=gallery-image data-flex-grow=170 data-flex-basis=408px></p><p><strong>Contention 竞争</strong></p><p>使用树状结构来减少竞争。</p><p><img src=/p/cs149_2024_note/figures/image-20250817145046657.png width=1788 height=622 srcset="/p/cs149_2024_note/figures/image-20250817145046657_hu_9b98ebae308f179d.png 480w, /p/cs149_2024_note/figures/image-20250817145046657_hu_27914a2eb929d933.png 1024w" loading=lazy alt=更新共享参数 class=gallery-image data-flex-grow=287 data-flex-basis=689px></p><p><strong>总结</strong></p><ul><li><p>减少通信开销</p><p>发更少、更大的消息（均摊开销），具体地，合并小消息成大消息</p></li><li><p>降低通信延迟</p><p>重构代码来利用局部性，硬件上提升通信架构</p></li><li><p>降低竞争</p><p>复制被竞争的资源（本地副本、细粒度锁），错开访问</p></li><li><p>提升通信/计算重叠</p><p>异步通信，硬件上流水线、多线程、预抓取、乱序执行，并发性大于执行单元数量</p></li></ul><p><strong>总是从最简单的并行实现开始，再去测量你所达到的性能。</strong></p><p><strong>性能分析策略</strong></p><p>确认你的性能是被<strong>计算、内存带宽、内存延迟、同步</strong>限制了？</p><p>&ldquo;high watermarks&rdquo;：实际上你最好能做到多少，距离最好的情况差多少？</p><p><strong>Roofline model</strong></p><p>屋顶线模型 - X-axis 计算强度、Y-axis 最大可获得的指令吞吐量</p><p><img src=/p/cs149_2024_note/figures/image-20250817150613506.png width=1556 height=854 srcset="/p/cs149_2024_note/figures/image-20250817150613506_hu_954860e18931474c.png 480w, /p/cs149_2024_note/figures/image-20250817150613506_hu_1027c854fc0a1ec3.png 1024w" loading=lazy alt="optimization regions" class=gallery-image data-flex-grow=182 data-flex-basis=437px></p><p><strong>建立 high watermarks</strong></p><ul><li><p>增加不涉及内存的命令</p><p>如果执行时间线性增长，代码瓶颈是指令速率。</p></li><li><p>去除大部分计算，读取相同的数据</p><p>执行时间如果没有降低多少，则可能是内存瓶颈。</p></li><li><p>把所有的数组访问变成 A[0]</p><p>变快很多的话，考虑提高数据访问局部性。</p></li><li><p>去除所有原子操作 / 锁</p><p>如果快了很多（保持相同的工作量），瓶颈在同步开销。</p></li></ul><p><strong>使用 profilers / performance monitoring 工具</strong></p><p>如 instructions completed, clock ticks, L2/L3 cache hits/misses, bytes read from memory controller, etc.</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-cpp data-lang=cpp><span class=line><span class=cl><span class=c1>// Intel&#39;s Performance Counter Monitor Tool, C++ API
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>PCM</span> <span class=o>*</span><span class=n>m</span> <span class=o>=</span> <span class=n>PCM</span><span class=o>::</span><span class=n>getInstance</span><span class=p>();</span>
</span></span><span class=line><span class=cl><span class=n>SystemCounterState</span> <span class=n>begin</span> <span class=o>=</span> <span class=n>getSystemCounterState</span><span class=p>();</span>
</span></span><span class=line><span class=cl><span class=c1>// code to analyze goes here
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>SystemCounterState</span> <span class=n>end</span> <span class=o>=</span> <span class=n>getSystemCounterState</span><span class=p>();</span>
</span></span><span class=line><span class=cl><span class=n>printf</span><span class=p>(</span><span class=err>“</span><span class=n>Instructions</span> <span class=n>per</span> <span class=nl>clock</span><span class=p>:</span> <span class=o>%</span><span class=n>f</span><span class=err>\</span><span class=n>n</span><span class=err>”</span><span class=p>,</span> <span class=n>getIPC</span><span class=p>(</span><span class=n>begin</span><span class=p>,</span> <span class=n>end</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=n>printf</span><span class=p>(</span><span class=err>“</span><span class=n>L3</span> <span class=n>cache</span> <span class=n>hit</span> <span class=nl>ratio</span><span class=p>:</span> <span class=o>%</span><span class=n>f</span><span class=err>\</span><span class=n>n</span><span class=err>”</span><span class=p>,</span> <span class=n>getL3CacheHitRatio</span><span class=p>(</span><span class=n>begin</span><span class=p>,</span> <span class=n>end</span><span class=p>));</span>
</span></span><span class=line><span class=cl><span class=n>printf</span><span class=p>(</span><span class=err>“</span><span class=n>Bytes</span> <span class=nl>read</span><span class=p>:</span> <span class=o>%</span><span class=n>d</span><span class=err>\</span><span class=n>n</span><span class=err>”</span><span class=p>,</span> <span class=n>getBytesReadFromMC</span><span class=p>(</span><span class=n>begin</span><span class=p>,</span> <span class=n>end</span><span class=p>));</span>
</span></span></code></pre></td></tr></table></div></div><p><strong>理解任务规模问题</strong></p><p>绝对表现（时间、每秒操作数），加速比、高效（每面积、钱、瓦）</p><p><strong>陷阱：固定任务规模的加速比</strong></p><p>不同规模，相同算法的表现不同。</p><p>（如前面的 2D 分配方式，在 N 小 P 大的时候，反而可能不如原本最差的版本）</p><p><img src=/p/cs149_2024_note/figures/image-20250817152811346.png width=1832 height=1144 srcset="/p/cs149_2024_note/figures/image-20250817152811346_hu_df8bacd5388a642b.png 480w, /p/cs149_2024_note/figures/image-20250817152811346_hu_94765277604911ae.png 1024w" loading=lazy alt="solver execution" class=gallery-image data-flex-grow=160 data-flex-basis=384px></p><p>超线性的加速比（对 cache 合适的配置）</p><p><img src=/p/cs149_2024_note/figures/image-20250817153039139.png width=1068 height=1042 srcset="/p/cs149_2024_note/figures/image-20250817153039139_hu_dfc6036efdf5765b.png 480w, /p/cs149_2024_note/figures/image-20250817153039139_hu_41c2c4a28915cf96.png 1024w" loading=lazy alt="super-linear supeedup" class=gallery-image data-flex-grow=102 data-flex-basis=245px></p><ul><li><p>所以，不同任务规模、不同并行规模在不同任务上有很大的不同。</p><p>load balance, overhead, arithmetic intensity, locality of data access</p></li><li><p>只用固定的任务大小来测试一台机器的方法是很有问题的。</p><p>过小的任务，并行开销大于并行好处；</p><p>未能充分利用大机器的优势。</p></li></ul><h3 id=general-program-optimization-tips>General program optimization tips</h3><ul><li>Measure, measure, measure&mldr; 测量评估</li><li>Establish high watermarks 找到瓶颈</li><li>意识到规模问题，任务是不是很好的匹配机器了？</li></ul><h2 id=gpu-architecture-and-cuda-programming>GPU Architecture and CUDA Programming</h2><h3 id=graphics-101--gpu-history-for-fun>Graphics 101 + GPU history (for fun)</h3><p>为了更好的渲染图形。</p><p>图形学的关键要素：<strong>顶点</strong>，<strong>基础图形</strong>（如线、三角形），<strong>片段</strong>，<strong>像素</strong>。</p><p><img src=/p/cs149_2024_note/figures/image-20250722204309293.png width=864 height=698 srcset="/p/cs149_2024_note/figures/image-20250722204309293_hu_4c878980443b42.png 480w, /p/cs149_2024_note/figures/image-20250722204309293_hu_dedcbb7d343595a6.png 1024w" loading=lazy alt=图形学的实体 class=gallery-image data-flex-grow=123 data-flex-basis=297px></p><ol><li>输入一系列<strong>三维顶点</strong>；</li><li>计算在<strong>二维屏幕</strong>的位置；</li><li>生成<strong>基础图形</strong>集合；</li><li>分割成片段，变成新的<strong>二维顶点集合；</strong></li><li>计算<strong>颜色</strong>。</li></ol><p><img src=/p/cs149_2024_note/figures/image-20250722205043117.png width=560 height=880 srcset="/p/cs149_2024_note/figures/image-20250722205043117_hu_aecd494c3be42284.png 480w, /p/cs149_2024_note/figures/image-20250722205043117_hu_129617e16a2abe6b.png 1024w" loading=lazy alt="图形流水线 (graphics pipeline)" class=gallery-image data-flex-grow=63 data-flex-basis=152px></p><p><strong>OpenGL API</strong>，调整材质的光泽等等。</p><p><strong>graphics shading language</strong></p><p><img src=/p/cs149_2024_note/figures/image-20250722210338238.png width=822 height=885 srcset="/p/cs149_2024_note/figures/image-20250722210338238_hu_e51f5ea07a1776c4.png 480w, /p/cs149_2024_note/figures/image-20250722210338238_hu_590763abea08803b.png 1024w" loading=lazy alt="graphics shading language (两个可编程的部分)" class=gallery-image data-flex-grow=92 data-flex-basis=222px></p><p>（粗糙的hack使用）</p><p><strong>GPU-based 的科学计算</strong></p><p>由于 CPU 的速度发展相对缓慢，开始把图形处理器用于科学计算。</p><p><strong>GPGPU 通用图形处理器</strong> 2002-2003</p><p>（编译器）</p><p><strong>Brook stream 编程语言</strong> 2004</p><p>编译成 OpenGL 命令。</p><p><strong>GPU ccompute mode</strong></p><p>不需要看作图形操作流水线的设备，而是作为大型数据并行的处理器。</p><p>在 2007 年之前，只能进行特殊的 ISA 操作。</p><p><strong>NVIDIA Tesla with CUDA</strong> 架构 2007</p><p>硬件上实现了数据并行</p><p>由最初开发 Brook 编译器的 PhD 移植到了 GPU 上。</p><p>&ldquo;C-like&rdquo; 语言，相对底层。</p><p>OpenCL 是 CUDA 的开放标准版本。</p><p>CUDA 只能在 NVIDIA GPU 上，OpenCL 可以在 CPU / GPU。</p><h3 id=cuda-program>CUDA program</h3><p>特别的 Thread 含义在 CUDA 编程语言的体系中，就如同 Program Instance 在 ISPC 的体系中的特殊语义，不等同 pThread 在 CPU 上。</p><p>层次化的并发线程集合模型。</p><p>二、三维，有出于一维确定各个维度，除法的开销大的考虑。</p><p><img src=/p/cs149_2024_note/figures/image-20250722214649269.png width=1057 height=637 srcset="/p/cs149_2024_note/figures/image-20250722214649269_hu_d805e75aa36b7f36.png 480w, /p/cs149_2024_note/figures/image-20250722214649269_hu_2b3e56bd37560d27.png 1024w" loading=lazy alt="CUDA 同步" class=gallery-image data-flex-grow=165 data-flex-basis=398px></p><p>线程的调度在硬件集成。</p><p>warp，线程束（CPU 类比 32-SIMD，GPU 32 独立执行上下文共享一条指令）</p><p>如果要求的线程数，超过了总可能的块内的线程数，无法编译，因为 <code>__syncthreads()</code>会形成死锁，等待。</p><p>创建直方图，不同块要访问同一个内存地址。</p><p><img src=/p/cs149_2024_note/figures/image-20250722223046992.png width=1113 height=890 srcset="/p/cs149_2024_note/figures/image-20250722223046992_hu_96e314aec4d0b796.png 480w, /p/cs149_2024_note/figures/image-20250722223046992_hu_8b317ce77374043f.png 1024w" loading=lazy alt=创建直方图 class=gallery-image data-flex-grow=125 data-flex-basis=300px></p><p>哪个是有效的代码。</p><p><img src=/p/cs149_2024_note/figures/image-20250722223702220.png width=1096 height=804 srcset="/p/cs149_2024_note/figures/image-20250722223702220_hu_b12cb81ec783e7f5.png 480w, /p/cs149_2024_note/figures/image-20250722223702220_hu_337afe47ea93253b.png 1024w" loading=lazy alt="CUDA code" class=gallery-image data-flex-grow=136 data-flex-basis=327px></p><h2 id=data-parallel-thinking>Data-Parallel Thinking</h2><p>对序列数据的操作。</p><h3 id=map-映射>Map 映射</h3><p>逐一对 $seq_a$ 每一位应用 $func()$ 输出到等长的 $seq_b$。</p><p><img src=/p/cs149_2024_note/figures/image-20250827151526181.png width=960 height=972 srcset="/p/cs149_2024_note/figures/image-20250827151526181_hu_c64cf1e12d1f53f8.png 480w, /p/cs149_2024_note/figures/image-20250827151526181_hu_6c199ca419c9d4bc.png 1024w" loading=lazy alt=Map class=gallery-image data-flex-grow=98 data-flex-basis=237px></p><p><strong>Parallelizing map</strong></p><p>以任意顺序应用，相互之间没有依赖。</p><h3 id=fold-归约fold-left从左到右>Fold 归约（fold left，从左到右）</h3><p>将二元操作依次应用。</p><p><img src=/p/cs149_2024_note/figures/image-20250827151555347.png width=2152 height=524 srcset="/p/cs149_2024_note/figures/image-20250827151555347_hu_fa57ee9b108aa6d2.png 480w, /p/cs149_2024_note/figures/image-20250827151555347_hu_329573cb703562c2.png 1024w" loading=lazy alt=Fold class=gallery-image data-flex-grow=410 data-flex-basis=985px></p><p><strong>Parallel fold</strong></p><p>无关运算合并先后的。</p><p><img src=/p/cs149_2024_note/figures/image-20250827151610204.png width=1566 height=720 srcset="/p/cs149_2024_note/figures/image-20250827151610204_hu_37f0e588f2433e7e.png 480w, /p/cs149_2024_note/figures/image-20250827151610204_hu_e7bce938eaccc69d.png 1024w" loading=lazy alt="Parallel fold" class=gallery-image data-flex-grow=217 data-flex-basis=522px></p><h3 id=scan-扫描>Scan 扫描</h3><p><strong>scan inclusive</strong></p><p>做前缀（二元操作），包含自己。</p><p><img src=/p/cs149_2024_note/figures/image-20250827151919079.png width=714 height=322 srcset="/p/cs149_2024_note/figures/image-20250827151919079_hu_5d2a283cc3a80271.png 480w, /p/cs149_2024_note/figures/image-20250827151919079_hu_cdde05c29f6e0055.png 1024w" loading=lazy alt="scan inclusive" class=gallery-image data-flex-grow=221 data-flex-basis=532px></p><p><strong>scan exclusive</strong></p><p>做前缀（二元操作），不包含自己。</p><p><strong>Parallel Scan</strong></p><p>无关运算合并先后的。</p><p><img src=/p/cs149_2024_note/figures/image-20250827152326894.png width=1692 height=1084 srcset="/p/cs149_2024_note/figures/image-20250827152326894_hu_7b37640224290ccd.png 480w, /p/cs149_2024_note/figures/image-20250827152326894_hu_1b7d06e8d5d2a2ba.png 1024w" loading=lazy alt="Parallel Scan" class=gallery-image data-flex-grow=156 data-flex-basis=374px></p><p>伪代码：</p><p><img src=/p/cs149_2024_note/figures/image-20250827152422535.png width=1022 height=882 srcset="/p/cs149_2024_note/figures/image-20250827152422535_hu_64396a6efa6e2c7f.png 480w, /p/cs149_2024_note/figures/image-20250827152422535_hu_81ae16b3e02d8b4e.png 1024w" loading=lazy alt="Parallel Scan" class=gallery-image data-flex-grow=115 data-flex-basis=278px></p><p>多个小块内部处理，再根据块 base 重建。</p><p><strong>Parallel Segmented Scan</strong></p><p>操作<strong>序列的序列</strong>。</p><p>[seq1, seq2, seq3]</p><p>同时传入长短不定的序列，都需要操作，比如 <code>scan_exclusive</code>。</p><p>如果不统一调度处理，很容易出现负载不均衡的情况。</p><p>增加开始标志 &ldquo;start-flag&rdquo;。</p><p>示意图：</p><p><img src=/p/cs149_2024_note/figures/image-20250827153447726.png width=1692 height=1080 srcset="/p/cs149_2024_note/figures/image-20250827153447726_hu_32933c1ded41b8cf.png 480w, /p/cs149_2024_note/figures/image-20250827153447726_hu_5f318a7ddd7ab8.png 1024w" loading=lazy alt="Segmented Scan" class=gallery-image data-flex-grow=156 data-flex-basis=376px></p><p>伪代码：</p><p><img src=/p/cs149_2024_note/figures/image-20250827153422169.png width=1410 height=902 srcset="/p/cs149_2024_note/figures/image-20250827153422169_hu_def35a8c43259354.png 480w, /p/cs149_2024_note/figures/image-20250827153422169_hu_4283e07c0be42bf0.png 1024w" loading=lazy alt="Segmented Scan" class=gallery-image data-flex-grow=156 data-flex-basis=375px></p><p>应用场景：</p><p><strong>稀疏矩阵乘法</strong></p><p><img src=/p/cs149_2024_note/figures/image-20250827153631208.png width=1628 height=996 srcset="/p/cs149_2024_note/figures/image-20250827153631208_hu_d6d70e0ecc4f6ed2.png 480w, /p/cs149_2024_note/figures/image-20250827153631208_hu_610bd44120a2547d.png 1024w" loading=lazy alt="Sparse matrix" class=gallery-image data-flex-grow=163 data-flex-basis=392px></p><h3 id=gather--scatter-聚集--分发>Gather / scatter 聚集 / 分发</h3><ul><li><p><strong>gather(index, input, output)</strong></p><p>output[i] = input[index[i]]</p></li><li><p><strong>scatter(index, input, output)</strong></p><p>output[index[i]] = input[i]</p></li></ul><p><img src=/p/cs149_2024_note/figures/image-20250827154012055.png width=1766 height=948 srcset="/p/cs149_2024_note/figures/image-20250827154012055_hu_742f8d7c3a4d7a97.png 480w, /p/cs149_2024_note/figures/image-20250827154012055_hu_126b5afe6a1c10ff.png 1024w" loading=lazy alt="Gather / scatter" class=gallery-image data-flex-grow=186 data-flex-basis=447px></p><p><strong>在某些条件下，可以把 Scatter 转化为 Gather</strong></p><p>假设索引中的元素是唯一的，并且索引中的所有元素都被引用（scatter = sort + gather）。</p><p>如果上面的条件不满足的时候（scatter = sort + map + gather）。</p><p>这种多个的组合在 <code>find_repeats</code> 中也能见到。</p><p><strong>更多序列操作</strong></p><ul><li><strong>Group by key</strong></li><li><strong>Filter</strong></li><li><strong>Sort</strong></li></ul><p><img src=/p/cs149_2024_note/figures/image-20250827155213101.png width=712 height=882 srcset="/p/cs149_2024_note/figures/image-20250827155213101_hu_e4d4f8ff6f7dd118.png 480w, /p/cs149_2024_note/figures/image-20250827155213101_hu_14f0412d5d93e5d9.png 1024w" loading=lazy alt="More sequence ops" class=gallery-image data-flex-grow=80 data-flex-basis=193px></p><p>应用场景：</p><ul><li>N 体问题</li><li>并行直方图</li></ul><p>CUDA 中的一个高效并行算法库：<strong>Thrust</strong></p><h2 id=distributed-data-parallel-computing-using-spark>Distributed Data-Parallel Computing Using Spark</h2><p>集群 Cluster 上的数据并行。</p><ul><li>Scalable，可规模化</li><li>Fault-tolerant，容错</li><li>Efficient，高效</li></ul><p>$\text{System MTTF (Mean Time to Failure)} = \frac{1}{\sum_{i=1}^{n}{\frac{1}{\text{MTTF}_i}}}$</p><p><strong>Storage System 存储系统</strong></p><p>如果节点 node 出现故障，如何持久地存储数据？</p><h3 id=distributed-file-system-分布式文件系统>Distributed File System 分布式文件系统</h3><p>提供全局文件命名空间 Global file namespace，如 Google GFS, Hadoop HDFS。</p><p><strong>典型使用模式</strong></p><ul><li>超大文件</li><li>数据很少就地更新</li><li>读取 read 和 附加 append 是最常见的，如 log 日志。</li></ul><p><strong>Distributed File System (GFS)</strong></p><ul><li><p><strong>块服务器 chunk server</strong></p><ul><li><strong>HDFS</strong> 中的 <strong>DataNodes</strong></li><li>文件被切分成连续块（常常 64 - 256 MB）</li><li>每个块都有副本（常常 2 - 3 份）</li><li>尽量把不同副本放入不同机架</li></ul></li><li><p>主节点 <strong>master node</strong></p><ul><li><strong>HDFS</strong> 中的 <strong>NameNode</strong></li><li>存储元数据；常常被复制副本</li></ul></li><li><p>客户端的文件访问库</p><ul><li>让主节点找到块（数据）服务器</li><li>和块服务器直连获取数据</li></ul></li></ul><p><strong>Hadoop Distributed File System (HDFS)</strong></p><p><img src=/p/cs149_2024_note/figures/image-20250827163556325.png width=1408 height=778 srcset="/p/cs149_2024_note/figures/image-20250827163556325_hu_3dade56969d7c722.png 480w, /p/cs149_2024_note/figures/image-20250827163556325_hu_2c304b8d914ce1e8.png 1024w" loading=lazy alt="Hadoop Distributed File System (HDFS)" class=gallery-image data-flex-grow=180 data-flex-basis=434px></p><p><strong>Message Passing Interface (MPI)</strong>，实现 Message Passing 模型的接口。</p><h3 id=mapreduce>MapReduce</h3><p>map + reduce (fold) => MapReduce</p><p><strong>作业调度的合理性</strong></p><ul><li><p>利用数据局部性，&ldquo;move coputation to the data&rdquo;</p><p>mapper 作业在包含输入块的节点上运行</p><p>reducer 作业在已经有某字段最多数据的节点上运行</p></li><li><p>解决节点故障</p><p>调度器检测作业故障并在新机器上重新运行作业。</p><p>因为输入是持久存储的。（分布式文件系统）</p><p>调度器在多个机器上复制任务。（降低处理故障产生的开销）</p></li><li><p>解决慢机器</p><p>调度器复制作业到多台机器上。</p></li></ul><p><strong>MapReduce 好处</strong></p><p>提供了数据并行的模型，简化了集群编程。</p><ul><li>将作业自动划分为 map 和 reduce 任务</li><li>局部感知调度</li><li>负载均衡</li><li>故障恢复、慢机器适应</li></ul><p><strong>问题</strong></p><ul><li>只支持简单的 map, reduce 编程结构</li><li>迭代算法每一次都要从硬盘中读数据</li></ul><p>用户需要更复杂、多阶段的应用。</p><h3 id=apache-spark>Apache Spark</h3><p><strong>in-memory, fault-tolerant distributed computing</strong></p><p>重用中间数据集的集群规模计算的编程模型。</p><p>不把中间数据写回持久分布式文件系统（不高效）</p><p><strong>in-memory calculation，容错怎么保证？</strong></p><ul><li><p>复制所有计算</p><p>成本高，降低峰值吞吐</p></li><li><p>检查点 Checkpoint 和回滚 rollback</p><p>定期存储到持久分布式文件系统</p><p>故障后从上一个检查点开始</p></li><li><p>维护日志 log 更新</p></li></ul><p><strong>MapReduce</strong></p><ul><li>在每步 map, reduce 后，都会建立 checkpoint</li><li>函数式结构允许只重启一个 map, reduce 任务，不需要整个程序重启</li></ul><p><strong>Resilient Distributed Dataset (RDD) 弹性分布式数据集</strong></p><p>Spark 的重要编程抽象</p><ul><li>只读记录有序集合（不可变）</li><li>RDDs 只能在对持久存储 / 现存 RDDs 进行确定的<strong>转换</strong> transformation 时被创建</li><li>RDDs 的 Action 操作把数据返回给应用</li></ul><p>一次性全读进来，并且在内存中存着，经过几个操作会比在硬盘中占的空间还大。</p><p>所以，考虑 loop fusion 和 &ldquo;streaming&rdquo;，流式处理，一次处理完一行数据。</p><p>能不能进行 fusing，需要看 Narrow dependencies / Wide dependencies （如 groupByKey），即是否不需要和别的节点通信。</p><p>使用 <code>PartitionBy</code> 可以控制划分的方法，在一些操作的使用上达到 Narrow dependencies 的效果。</p><p>通过血缘谱系 Lineage 来实现弹性 Resilience，运行时系统可以通过 Lineage 重建 RDD 的内容。</p><p>Lineage 是 Transformation 的 log，粗粒度，存储高效。</p><p><code>_.persist(RELIABLE)</code> 允许让在长 Lineage 中，设置 checkpoint。</p><p>规模化不是终点，COST = “Configuration that Outperforms a Single Thread”。</p><p>不仅追求规模化，更要有比单线程更好的效果，即也追求高性能。</p><h2 id=efficiently-evaluating-dnns-software-solutions>Efficiently Evaluating DNNs (Software Solutions)</h2><p>没太多新东西，特别是先做 PA 回头来看的话。</p><p>提到的一些优化方式，神经网络结构优化、算子优化（分块、融合）、压缩模型（低精度、稀疏化、剪枝）。</p><p>GPU 为什么是 DNN 的好平台？高计算强度、算力高、高性能库多。</p><p>GPU 为什么可能是次优的 DNN 平台？通用部分可能没那么需要。</p><h2 id=hardware-specialization>Hardware Specialization</h2><p>功耗限制型计算</p><p>专用硬件，追求更好的能耗比。</p><p>ASIC (Application-Specific Integrated Circuit)</p><p>FPGAs (Field Programmable Gate Arrays), Verilog</p><p>DSP (Digital Signal Processor)</p><p>介绍了一些专用硬件。</p><p>降低功耗：专用的处理单元、减少数据移动。</p><p>适当考虑重算，多考虑整数运算。</p><p>DRAM 的工作逻辑</p><p>[ Precharge (PRE, 用于传输的 bit line) + row activate (RAS, 待读取行) ] + column access (CAS)</p><p>data pins 利用率低，一个 DRAM 多个 bank 共享一个 data pins 流水线。</p><p>DIMM (Dual Inline Memory Module)</p><p>Dual-channel memory system 双通道内存</p><p>Simpler setup: use single controller to drive same command to multiple channels</p><p><img src=/p/cs149_2024_note/figures/image-20250828132711345.png width=1748 height=698 srcset="/p/cs149_2024_note/figures/image-20250828132711345_hu_5a32d88a3c3bf2da.png 480w, /p/cs149_2024_note/figures/image-20250828132711345_hu_c8c6b8f5fd46fb8d.png 1024w" loading=lazy alt="Dual-channel memory system" class=gallery-image data-flex-grow=250 data-flex-basis=601px></p><p>DDR (double data rate)</p><p>HBM (High-bandwidth memory)，高带宽，高能效，小体积。</p><p>内存瓶颈的解决方式：</p><p>应用工程师：编程局部性</p><p>硬件架构：DRAM 调度、距离更近、计算移到内存中、数据压缩。</p><h2 id=programming-specialized-hardware>Programming Specialized Hardware</h2><p>TPU - Systolic array 脉动阵列，很有节奏感了。</p><p><img src=/p/cs149_2024_note/figures/image-20250828135204735.png width=1666 height=1134 srcset="/p/cs149_2024_note/figures/image-20250828135204735_hu_85a12ac8fad9fb15.png 480w, /p/cs149_2024_note/figures/image-20250828135204735_hu_99f50b7f51b5dc58.png 1024w" loading=lazy alt="Systolic array" class=gallery-image data-flex-grow=146 data-flex-basis=352px></p><p>TMA (Tensor Memory Accelerator)</p><p>ThunderKittens, A Simple Embedded DSL for AI kernels</p><p>设计原则</p><ul><li>16x16 Tile layouts</li><li>异步</li><li>GPU 协调模式，生产者 - 消费者</li></ul><p>MetaPipeline = Streaming Dataflow</p><p><img src=/p/cs149_2024_note/figures/image-20250828141815441.png width=1080 height=494 srcset="/p/cs149_2024_note/figures/image-20250828141815441_hu_b062c6834f44ea9c.png 480w, /p/cs149_2024_note/figures/image-20250828141815441_hu_13e07a16ddfd79eb.png 1024w" loading=lazy alt=MetaPipeline class=gallery-image data-flex-grow=218 data-flex-basis=524px></p><p>PCU: Pattern Compute Unit</p><p>PMU: Pattern Memory Unit</p><p>AGCU: Address Generator and Coalescing Unit</p><h2 id=programming-specialized-hardware-ii--cache-coherence>Programming Specialized Hardware II + Cache Coherence</h2><p>cache line</p><p><img src=/p/cs149_2024_note/figures/image-20250828143838388.png width=1476 height=364 srcset="/p/cs149_2024_note/figures/image-20250828143838388_hu_5060c9edd59afb81.png 480w, /p/cs149_2024_note/figures/image-20250828143838388_hu_e92d72f6f1ffa727.png 1024w" loading=lazy alt="cache line" class=gallery-image data-flex-grow=405 data-flex-basis=973px></p><p><strong>Write-Through</strong>（写通）：</p><p>当应用程序执行写操作时，数据会同时写入缓存和主存储器。﻿</p><p>数据一致性，但要写两次。</p><p><strong>Write-Back</strong>（回写）﻿：</p><p>写操作仅更新缓存，并标记为“脏数据”。只有当缓存中的脏数据块即将被另一个缓存块替换时，才会被一次性写入主存储器。</p><p>数据不一致，数据丢失风险。</p><p><strong>write-allocate</strong>，会先将数据块从主内存读取到缓存中再写入；</p><p><strong>write-no-allocate</strong>，则直接将写入操作执行到主内存，不将数据加载到缓存。﻿</p><p>缓存未命中 cache miss 的 3 C：cold, capacity, conflict。</p><p>缓存一致性 cache coherence，缓存 cache 和内存 main memory 之间的不同。</p><p>单写者-多读者不变量 Single-Writer, Multiple-Reader (SWMR) Invariant</p><p>shared cache，简单，但是在 cache 上竞争 contention</p><p>write-through 方法，简单，但是其他 local cache 都失效了</p><p>write-back 方法，当写入 cache 后缓存只是合法副本的缓存，变成独自 exclusive 的所有权，当别的处理器要读取这个数据时，它要送过去。</p><p>“modified” 状态，不需要通知别人，因为它肯定是不合法的。</p><p>由 cache controller 来控制。</p><p><strong>MSI write-back invalidation protocol</strong></p><p>三种状态：</p><p>Modified (M): line valid in exactly one cache (a.k.a. “dirty” or “exclusive” state)</p><p>Shared (S): line valid in one or more caches, memory is up to date</p><p>Invalid (I): same as meaning of invalid in uniprocessor cache</p><p>PrRd (read)</p><p>PrWr (write)</p><p>BusRd: obtain copy of line with no intent to modify</p><p>BusRdX: obtain copy of line with intent to modify</p><p>BusWB: write dirty line out to memory</p><p><img src=/p/cs149_2024_note/figures/image-20250828205400227.png width=1752 height=854 srcset="/p/cs149_2024_note/figures/image-20250828205400227_hu_ad39f5f7a4661d39.png 480w, /p/cs149_2024_note/figures/image-20250828205400227_hu_5823c224293df860.png 1024w" loading=lazy alt="MSI 状态图" class=gallery-image data-flex-grow=205 data-flex-basis=492px></p><p><strong>Obtain exclusive ownership before writing</strong></p><p>BusRdX causes others to invalidate</p><p>If M in another cache, will cause writeback</p><p>BusRdX even if hit in S - promote to M (upgrade)</p><p>只能在 M 状态写入，需要告诉 cache controller，现在独占读入权，要写入，其他不能读。</p><p><strong>MESI invalidation protocol</strong></p><p>对于常见的读后写，需要两个转换，I ==BusRd=> S ==BusRdX=> M，在不共享的时候也存在。</p><p>增加 E (exclusive clean) ，独占权 exclusivity 和所有权 ownership 分离。（合法的副本）</p><p><img src=/p/cs149_2024_note/figures/image-20250828210447214.png width=1722 height=1130 srcset="/p/cs149_2024_note/figures/image-20250828210447214_hu_228a962036e9ffff.png 480w, /p/cs149_2024_note/figures/image-20250828210447214_hu_4fb7c133c37b7dd9.png 1024w" loading=lazy alt="MESI 状态图" class=gallery-image data-flex-grow=152 data-flex-basis=365px></p><p>广播 broadcast，不可规模化；</p><p>目录 directory，可规模化。</p><p>只是发送一致性信息。</p><p>$\text{Average Memory Access Time (AMAT) }= \sum_0^n{\text{frequency of access} \cross \text{latency of access}}$</p><p>多处理器的 MAT 会增加。</p><p><img src=/p/cs149_2024_note/figures/image-20250829084731994.png width=822 height=405 srcset="/p/cs149_2024_note/figures/image-20250829084731994_hu_e63cf887099af8e5.png 480w, /p/cs149_2024_note/figures/image-20250829084731994_hu_3fabbd915e5df6c6.png 1024w" loading=lazy alt="Frequency of access" class=gallery-image data-flex-grow=202 data-flex-basis=487px></p><p>工具：<strong>VTune</strong></p><p>预期外的通信：伪共享 false sharing</p><p>cache 是以 cache line 为单位的。</p><p>所以，代码一，实际不同线程之间会反复「竞争」一个线程；</p><p>代码二，对 cache line 进行补全，不会「竞争」。</p><p><img src=/p/cs149_2024_note/figures/image-20250829085245136.png width=1372 height=792 srcset="/p/cs149_2024_note/figures/image-20250829085245136_hu_a342ea99cf244ac4.png 480w, /p/cs149_2024_note/figures/image-20250829085245136_hu_45cad4b262af46f0.png 1024w" loading=lazy alt="false sharing" class=gallery-image data-flex-grow=173 data-flex-basis=415px></p><p><img src=/p/cs149_2024_note/figures/image-20250829085611910.png width=1659 height=1107 srcset="/p/cs149_2024_note/figures/image-20250829085611910_hu_1d160f40f1ad1d.png 480w, /p/cs149_2024_note/figures/image-20250829085611910_hu_cbb7818b29ce8c81.png 1024w" loading=lazy alt="false sharing 例一" class=gallery-image data-flex-grow=149 data-flex-basis=359px></p><p><img src=/p/cs149_2024_note/figures/image-20250829085721422.png width=475 height=527 srcset="/p/cs149_2024_note/figures/image-20250829085721422_hu_2d79b89ef30fe46d.png 480w, /p/cs149_2024_note/figures/image-20250829085721422_hu_11ee2034e76e0a3f.png 1024w" loading=lazy alt="false sharing 例二" class=gallery-image data-flex-grow=90 data-flex-basis=216px></p><p>缓存一致性的问题出现的原因是，单位共享地址的抽象与单个存储单位的实现不一致。</p><p>基于侦听 snooping-based 的缓存一致性方法，每当有可能影响 cache coherence 的操作，就会广播。</p><p>HW，减少 coherence 的开销；SW，警惕人工引入的由一致性协议 coherence protocol 引起的通信。</p><p>规模化 scalable 的 cache conherence，使用基于目录 cache coherence 的方法。</p><h2 id=cache-coherence>Cache Coherence</h2><p><strong>Memory Consistency</strong></p><p>缓存一致性和内存连贯性。</p><p>cache coherence 是多副本的一致性；memory consistency 是多个内存操作执行顺序的连贯性（一致性）。</p><p>synchronization library / kernel / lock-free ds</p><p><em><strong>Memory coherence</strong> defines requirements for the observed behavior of reads and writes to the <strong>same</strong> memory location.</em></p><p><em><strong>Memory consistency</strong> defines the behavior of reads and writes to <strong>different</strong> locations (as observed by other processors).</em></p><p><img src=/p/cs149_2024_note/figures/image-20250829093950594.png width=1765 height=1010 srcset="/p/cs149_2024_note/figures/image-20250829093950594_hu_8ebfa7a54eedc14c.png 480w, /p/cs149_2024_note/figures/image-20250829093950594_hu_ce5cf8955c53a4da.png 1024w" loading=lazy alt="MC vs. MC" class=gallery-image data-flex-grow=174 data-flex-basis=419px></p><p><img src=/p/cs149_2024_note/figures/image-20250829094151294.png width=1606 height=982 srcset="/p/cs149_2024_note/figures/image-20250829094151294_hu_23f6162550ce1f64.png 480w, /p/cs149_2024_note/figures/image-20250829094151294_hu_efca3aebbc633710.png 1024w" loading=lazy alt="C vs. C" class=gallery-image data-flex-grow=163 data-flex-basis=392px></p><p><img src=/p/cs149_2024_note/figures/image-20250829094259986.png width=1649 height=656 srcset="/p/cs149_2024_note/figures/image-20250829094259986_hu_a8ec9cfde7abef30.png 480w, /p/cs149_2024_note/figures/image-20250829094259986_hu_74dd6063abd47cb3.png 1024w" loading=lazy alt=MC class=gallery-image data-flex-grow=251 data-flex-basis=603px></p><p>Sequential Consistency</p><p>顺序保障，但是为了提高性能，选择重排。</p><p><strong>write buffer</strong>，放松了 W-R 先写后读。</p><p>TSO (Total Store Order)</p><p>PSO (Partial Store Ordering)，加锁类似。</p><p><strong>these are all valid optimizations if a program consists of a single instruction stream</strong></p><p>Weak ordering (WO)</p><p>Release Consistency (RC)</p><p>同步 synchronization 来挽救。</p><p>Fence (memory barrier), read-modify-write/compare-and-swap, transactional memory, …</p><p><strong>Intel x86/x64 ~ total store ordering</strong></p><p>提供特定的指令去说明，指令不需要保证顺序。</p><p>mm_lfence (“load fence”: wait for all loads to complete)</p><p>mm_sfence (“store fence”: wait for all stores to complete)</p><p>mm_mfence (“mem fence”: wait for all me operations to complete)</p><p><strong>ARM processors: very relaxed consistency model</strong></p><p>data race free (DRF)</p><h2 id=lock-implementations-fine-grained-synchronization-and-lock-free-programming>Lock Implementations, Fine-Grained Synchronization and Lock-Free Programming</h2><p>死锁 Deadlock，正确性，有未完成的任务需要完成， 但是没有操作可以进行。</p><p>活锁 Livelock，正确性，一直在做无意义的操作， abort and retry。</p><p>饥饿 Starvation，公平性，一个任务处理，其他任务没有操作。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Test-and-set based lock (Atomic)</span>
</span></span><span class=line><span class=cl>ts R0, mem<span class=o>[</span>addr<span class=o>]</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>load mem<span class=o>[</span>addr<span class=o>]</span> into R0
</span></span><span class=line><span class=cl><span class=k>if</span> mem<span class=o>[</span>addr<span class=o>]</span> is 0, <span class=nb>set</span> mem<span class=o>[</span>addr<span class=o>]</span> to <span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># x86 cmpxchg</span>
</span></span><span class=line><span class=cl><span class=c1># Compare and exchange (atomic when used with lock prefix)</span>
</span></span><span class=line><span class=cl>lock cmpxchg dst, src
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=o>(</span><span class=nv>dst</span> <span class=o>==</span> EAX<span class=o>)</span>
</span></span><span class=line><span class=cl>  <span class=nv>ZF</span> <span class=o>=</span> <span class=m>1</span>
</span></span><span class=line><span class=cl>  <span class=nv>dst</span> <span class=o>=</span> src
</span></span><span class=line><span class=cl><span class=k>else</span>
</span></span><span class=line><span class=cl>  <span class=nv>ZF</span> <span class=o>=</span> <span class=m>0</span>
</span></span><span class=line><span class=cl>  <span class=nv>EAX</span> <span class=o>=</span> dst
</span></span></code></pre></td></tr></table></div></div><p>线程越多，lock 的 contention 越激烈，时间越长。</p><p><strong>Test-and-test-and-set</strong>，在 lock free 之前，while 等待；公平性没有保证。</p><p>less traffic &lt;=> more scalable</p><p><strong>ticket lock</strong>，等待 lock free，取票，等 unlock 叫号。</p><p>compare and swap</p><p>fetch-and-op</p><p>Lock-free queue (bound / unbound)</p><p>Lock-free stack</p><p>CAS (compare_and_swap)</p><p>double compare and swap</p><p><strong>“读取-尝试-重试”的循环是无锁编程的标志性模式。</strong></p><p>while + CAS</p><p>无锁是用如原子操作的底层方式来保证线程安全。</p><h2 id=relaxed-consistency--domain-specific-programming-systems>Relaxed Consistency + Domain-Specific Programming Systems</h2><h3 id=relaxed-memory-consistency>relaxed memory consistency</h3><p>见 Cache Coherence。</p><h3 id=dsl-domain-specific-programming-languages>DSL (Domain-Specific programming languages)</h3><p><strong>Halide</strong>, for image processing.</p><p>不是为新手准备的，提供了一系列的用于优化的原语。</p><p>系统搭建的关键，为作业选择合适的再现方式。</p><p><strong>Choosing the “right” representations for the job</strong></p><p>自然、可靠、性能；调度（呈现成骨架、草图、pipeline 的感觉）</p><p><strong>Lizst</strong>, PDE’s on meshes.</p><p>编译器决定用什么数据结构。</p><p>可迁移，CPU, GPU 采用不同的算法。</p><p>把握最重要的元素、简单的系统、原语组合。</p><h2 id=transactional-memory>Transactional Memory</h2><p>事务内存，另一种同步抽象，声明式 declarative，如 <code>atomic{}</code>。</p><p>命令式 Imperative</p><p>atomic { } ≠ lock() + unlock()</p><p>数据版本控制策略 data versioning policy</p><ul><li>Eager versioning (<strong>undo-log based</strong>)</li><li>Lazy versioning (<strong>write-buffer based</strong>)</li></ul><p><strong>Pessimistic Conflict Detection</strong> (悲观冲突检测)</p><p>&ldquo;Eager&rdquo; (主动的)</p><p><strong>Optimistic Conflict Detection</strong> (乐观冲突检测)</p><p>&ldquo;Lazy&rdquo; (懒惰的) 或 &ldquo;Commit&rdquo; (提交时)</p><p>STM (Software Transactional Memory)</p><h2 id=transactions-ii--ask-me-anything-with-kayvon-and-kunle>Transactions II + Ask Me Anything with Kayvon and Kunle</h2><p><strong>Hardware transactional memory</strong> (HTM)</p><p>Data versioning is implemented in caches</p><p>Conflict detection through cache coherence protocol</p></section><footer class=article-footer><section class=article-tags><a href=/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>学习笔记</a>
<a href=/tags/cs149/>CS149</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>最后更新于 2025 年 8 月 30 日 14:10 CST</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>相关文章</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/cs149_2024_asst5_writeup/><div class=article-image><img src=/p/cs149_2024_asst5_writeup/cover.6e334527582f43c21afa8b753f42b50c_hu_4c45e10e34ec4af0.jpeg width=250 height=150 loading=lazy alt="Featured image of post 『学习笔记』CS149 (2024): Assignment 5" data-key=CS149_2024_asst5_writeup data-hash="md5-bjNFJ1gvQ8Ia+ot1P0K1DA=="></div><div class=article-details><h2 class=article-title>『学习笔记』CS149 (2024): Assignment 5</h2></div></a></article><article class=has-image><a href=/p/cs149_2023_asst4_writeup/><div class=article-image><img src=/p/cs149_2023_asst4_writeup/cover.453a3cd0fcebc0cb8b795998eb6cf804_hu_205eea90320f6d46.jpeg width=250 height=150 loading=lazy alt="Featured image of post 『学习笔记』CS149 (2023): Assignment 4" data-key=CS149_2023_asst4_writeup data-hash="md5-RTo80PzrwMuLeVmY62z4BA=="></div><div class=article-details><h2 class=article-title>『学习笔记』CS149 (2023): Assignment 4</h2></div></a></article><article class=has-image><a href=/p/cs149_2024_asst2_writeup/><div class=article-image><img src=/p/cs149_2024_asst2_writeup/cover.ed99683fe0aa2485b30fae87122488f3_hu_d95c17e058883c72.jpg width=250 height=150 loading=lazy alt="Featured image of post 『学习笔记』CS149 (2024): Assignment 2" data-key=CS149_2024_asst2_writeup data-hash="md5-7ZloP+CqJIWzD66HEiSI8w=="></div><div class=article-details><h2 class=article-title>『学习笔记』CS149 (2024): Assignment 2</h2></div></a></article><article class=has-image><a href=/p/cs149_2024_asst3_writeup/><div class=article-image><img src=/p/cs149_2024_asst3_writeup/cover.344cb5abcc4fda0b40fad57d018ed737_hu_b4d264c56e73b42e.jpeg width=250 height=150 loading=lazy alt="Featured image of post 『学习笔记』CS149 (2024): Assignment 3" data-key=CS149_2024_asst3_writeup data-hash="md5-NEy1q8xP2gtA+tV9AY7XNw=="></div><div class=article-details><h2 class=article-title>『学习笔记』CS149 (2024): Assignment 3</h2></div></a></article><article class=has-image><a href=/p/cs149_2024_asst1_writeup/><div class=article-image><img src=/p/cs149_2024_asst1_writeup/cover.7bf451ad35840d07dd26719063b8bb38_hu_da9fe0c3b76dc74b.jpg width=250 height=150 loading=lazy alt="Featured image of post 『学习笔记』CS149 (2024): Assignment 1" data-key=CS149_2024_asst1_writeup data-hash="md5-e/RRrTWEDQfdJnGQY7i7OA=="></div><div class=article-details><h2 class=article-title>『学习笔记』CS149 (2024): Assignment 1</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=Livinfly/Livinfly.github.io data-repo-id=R_kgDON6qCKA data-category=Announcements data-category-id=DIC_kwDON6qCKM4CnBxR data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=top data-theme=light data-lang=zh-CN data-loading crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark")}})()</script><footer class=site-footer><section class=copyright>&copy;
2022 -
2025 Livinfly's Blog</section><section class=powerby>使用 <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> 构建<br>主题 <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.31.0>Stack</a></b> 由 <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> 设计</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>